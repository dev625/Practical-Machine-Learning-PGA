---
title: "Week-4-PGA"
author: "Devesh Lohumi"
date: "24/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

## Aim
### Use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants and quantify how much work they do.  

## Preprocessing the data
```{r preprocessing,echo=TRUE,warning=FALSE}
# Load the required libraries
library(ggplot2)
library(lattice)
library(caret)
library(kernlab)
library(rattle)
library(corrplot)
set.seed(12)  #for reproducibility
```

## Loading the data
The two training and testing csv files can be directly downloaded from the
source and then read into data frames.
```{r loading,echo=TRUE,cache=TRUE}
train_csv <- read.csv("./pml-training.csv")
test_csv  <- read.csv("./pml-testing.csv")
dim(train_csv)
dim(test_csv)
```
As can be seen above :  
1. Training data has dimensions 19622 X 160.  
2. Testing data has dimensions 20 X 160.  
3. The first dimension is the number of observations.  

## Cleaning the data
We can start with removing the NA variables.
```{r cleaning1,echo=TRUE,cache=TRUE}
# Initially we remove the NA columns
train_csv <- train_csv[,colMeans(is.na(train_csv))< .9]
# Also on observing the head of the data it is seen that, the
# first seven cols are just metadata and hence are irrelevant
# to any outcome
train_csv <- train_csv[,-c(1:7)]
```


A zero variance indicates that all values within the set of a numbers are identical. Hence we can safely remove these values.
```{r cleaning2,echo=TRUE,cache=TRUE}
nvz_check <- nearZeroVar(train_csv)
train_csv <- train_csv[,-nvz_check]
dim(train_csv)
```

Now we can perform a standard split of the data-set into training and
validation sets. We'll use training set for training our models and the validation set of testing purposes.

```{r splitting,echo=TRUE,cache=TRUE}
factor <- createDataPartition(y=train_csv$classe,p=0.7,list=F)
train_data <- train_csv[factor,]
valid_data <- train_csv[-factor,]
```

# Creating and Testing the Models

```{r setup1,echo=TRUE,cache=TRUE}
# trainControl command controls the computational nuances of the
# train function.We use the cross validation method here and set
# the number of iterations to 3 and don't print the training log
control <- trainControl(method="cv", number=3, verboseIter=F)
```

## Methodology
### We use the train function which sets up a grid of tuning parameters for a number of classification and regression routines, fits each model and calculates a resampling based performance measure.  
### We also use the prefict function which predicts the values based on the input data.

## Decision Tree
Code for the Model:
```{r dtmodel1,echo=TRUE, cache = TRUE}
model_trees <- train(classe~., data=train_data, method="rpart", trControl = control, tuneLength = 5)
fancyRpartPlot(model_trees$finalModel)
```
Code for the Prediction:
```{r dtmodel2,echo=TRUE, cache = TRUE}
pred_trees <- predict(model_trees, valid_data)
matrix_trees <- confusionMatrix(pred_trees, factor(valid_data$classe))
matrix_trees
```

## Random Forest Classifier
```{r rfmodel,echo=TRUE,cache=TRUE}
rf_model <- train(classe~., data=train_data, method="rf", trControl = control, tuneLength = 5)
rf_prediction <- predict(rf_model, valid_data)
matrix_rf <- confusionMatrix(rf_prediction, factor(valid_data$classe))
matrix_rf
```

## Gradient Boosted Trees Classifier
```{r gbt,echo=TRUE,cache=TRUE}
gbt_model <- train(classe~., data=train_data, method="gbm", trControl = control, tuneLength = 5, verbose = F)
gbt_prediction <- predict(gbt_model, valid_data)
matrix_gbt <- confusionMatrix(gbt_prediction, factor(valid_data$classe))
matrix_gbt
```

## Support Vector Machine Classifier

```{r svm,echo=TRUE,cache=TRUE}
svm_model <- train(classe~., data=train_data, method="svmLinear", trControl = control, tuneLength = 5, verbose = F)
svm_prediction <- predict(svm_model, valid_data)
matrix_svm <- confusionMatrix(svm_prediction, factor(valid_data$classe))
matrix_svm
```

## Prediction using the Test Dataset

### We use the random forest classifier here because it provides a **higher accuracy**
through cross validation and handles the missing values and maintains the accuracy of a large
proportion of data.

```{r prediction1,echo=TRUE,cache=TRUE}
final <- predict(rf_model,test_csv)
print(final)
```

## Appendix : Figures
### 1.Correlation Matrix of Training Set Variables  
```{r ap1, cache = T}
corr <- cor(train_data[, -length(names(train_data))])
corrplot(corr, method="color")
```
### 2.Plotting the models

**Decision Tree**
```{r ap2,echo=TRUE,cache = TRUE}
plot(model_trees)
```

**Random Forest**
```{r ap3,echo=TRUE,cache = TRUE}
plot(rf_model)
```

**Gradient Boosted Tree**
```{r ap4,echo=TRUE,cache = TRUE}
plot(gbt_model)
```